{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Build a sentiment analysis pipeline with HuggingFace"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:44.894932Z","iopub.status.busy":"2023-10-05T01:28:44.894602Z","iopub.status.idle":"2023-10-05T01:28:53.396503Z","shell.execute_reply":"2023-10-05T01:28:53.395341Z","shell.execute_reply.started":"2023-10-05T01:28:44.894905Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (4.33.2)\n","Requirement already satisfied: filelock in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from transformers) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from transformers) (2023.8.8)\n","Requirement already satisfied: requests in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.8.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from requests->transformers) (2.0.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/mprotect/anaconda3/envs/myfast/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"]}],"source":["#for colab\n","!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:53.399472Z","iopub.status.busy":"2023-10-05T01:28:53.399069Z","iopub.status.idle":"2023-10-05T01:28:53.403849Z","shell.execute_reply":"2023-10-05T01:28:53.402951Z","shell.execute_reply.started":"2023-10-05T01:28:53.399433Z"},"trusted":true},"outputs":[],"source":["from transformers import pipeline\n","import torch\n","from pprint import pprint"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:53.406151Z","iopub.status.busy":"2023-10-05T01:28:53.405209Z","iopub.status.idle":"2023-10-05T01:28:54.358669Z","shell.execute_reply":"2023-10-05T01:28:54.357728Z","shell.execute_reply.started":"2023-10-05T01:28:53.406120Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n"]}],"source":["classifier = pipeline(\"sentiment-analysis\")"]},{"cell_type":"markdown","metadata":{},"source":["We start by creating a \"Sentiment Analysis\" **classifier** using the pipeline function provided by the Hugging Face Transformers library. This function allows us to easily use pre-trained models for various natural language processing (NLP) tasks, like sentiment analysis."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:54.361836Z","iopub.status.busy":"2023-10-05T01:28:54.360980Z","iopub.status.idle":"2023-10-05T01:28:54.408540Z","shell.execute_reply":"2023-10-05T01:28:54.407588Z","shell.execute_reply.started":"2023-10-05T01:28:54.361802Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9998584985733032}]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["results = classifier(\"This is cool\")\n","results"]},{"cell_type":"markdown","metadata":{},"source":["The model takes this text as input and predicts the sentiment associated with it. "]},{"cell_type":"markdown","metadata":{},"source":["Pipeline on Huggingface [documentation](https://huggingface.co/docs/transformers/main_classes/pipelines)"]},{"cell_type":"markdown","metadata":{},"source":["### More then one sentence"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:54.410534Z","iopub.status.busy":"2023-10-05T01:28:54.410001Z","iopub.status.idle":"2023-10-05T01:28:54.508009Z","shell.execute_reply":"2023-10-05T01:28:54.507107Z","shell.execute_reply.started":"2023-10-05T01:28:54.410502Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9997960925102234},\n"," {'label': 'POSITIVE', 'score': 0.9995623230934143}]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# We give a list to the classifier now\n","results = classifier([\"NLP is nice\", \"It's a lot of work\"])\n","results"]},{"cell_type":"markdown","metadata":{},"source":["### Exercise:\n","\n","Add different text inputs with varying sentiments, run it, check the model's sentiment predictions, and explore how it assigns labels."]},{"cell_type":"markdown","metadata":{},"source":["## Now select a specific model into your pipeline"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:54.509823Z","iopub.status.busy":"2023-10-05T01:28:54.509514Z","iopub.status.idle":"2023-10-05T01:28:54.514246Z","shell.execute_reply":"2023-10-05T01:28:54.513239Z","shell.execute_reply.started":"2023-10-05T01:28:54.509792Z"},"trusted":true},"outputs":[],"source":["model_name = \"distilbert-base-uncased-finetuned-sst-2-english\""]},{"cell_type":"markdown","metadata":{},"source":["The model_name variable holds the name of the pre-trained model. In this case, it's \"distilbert-base-uncased-finetuned-sst-2-english\""]},{"cell_type":"markdown","metadata":{},"source":["Let's have a look at the model [card on Hugginface.co](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:54.516392Z","iopub.status.busy":"2023-10-05T01:28:54.515806Z","iopub.status.idle":"2023-10-05T01:28:55.355163Z","shell.execute_reply":"2023-10-05T01:28:55.354221Z","shell.execute_reply.started":"2023-10-05T01:28:54.516361Z"},"trusted":true},"outputs":[],"source":["classifier = pipeline(\"sentiment-analysis\", model=model_name)"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenizer"]},{"cell_type":"markdown","metadata":{},"source":["- Tokenization is the process of breaking down text into smaller **units** called **tokens**.\n","\n","- Tokens are the basic building blocks used by Transformers models to understand and process text.\n","\n","- Tokens can represent **words, subwords, or even individual characters**, depending on the model's vocabulary."]},{"cell_type":"markdown","metadata":{},"source":["![Pipeline](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg)"]},{"cell_type":"markdown","metadata":{},"source":["Source [image](https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:55.356719Z","iopub.status.busy":"2023-10-05T01:28:55.356390Z","iopub.status.idle":"2023-10-05T01:28:55.361422Z","shell.execute_reply":"2023-10-05T01:28:55.360527Z","shell.execute_reply.started":"2023-10-05T01:28:55.356689Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification"]},{"cell_type":"markdown","metadata":{},"source":["\"AutoModelForSequenceClassification\" adapts to various model architectures automatically."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:55.363556Z","iopub.status.busy":"2023-10-05T01:28:55.362893Z","iopub.status.idle":"2023-10-05T01:28:56.082049Z","shell.execute_reply":"2023-10-05T01:28:56.081052Z","shell.execute_reply.started":"2023-10-05T01:28:55.363525Z"},"trusted":true},"outputs":[],"source":["model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"markdown","metadata":{},"source":["When using from_pretrained, we are loading a pre-trained model and tokenizer specified by the model_name."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.085867Z","iopub.status.busy":"2023-10-05T01:28:56.085563Z","iopub.status.idle":"2023-10-05T01:28:56.105959Z","shell.execute_reply":"2023-10-05T01:28:56.105136Z","shell.execute_reply.started":"2023-10-05T01:28:56.085844Z"},"trusted":true},"outputs":[],"source":["classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["We create our sentiment analysis classifier."]},{"cell_type":"markdown","metadata":{},"source":["## Tokens to inputs IDs"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.107623Z","iopub.status.busy":"2023-10-05T01:28:56.107285Z","iopub.status.idle":"2023-10-05T01:28:56.112778Z","shell.execute_reply":"2023-10-05T01:28:56.111516Z","shell.execute_reply.started":"2023-10-05T01:28:56.107593Z"},"trusted":true},"outputs":[],"source":["tokens = tokenizer.tokenize(\"Another cool sentence to demonstrate something.\")\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","input_ids = tokenizer(\"Another cool sentence to demonstrate something.\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.114684Z","iopub.status.busy":"2023-10-05T01:28:56.114134Z","iopub.status.idle":"2023-10-05T01:28:56.124564Z","shell.execute_reply":"2023-10-05T01:28:56.123480Z","shell.execute_reply.started":"2023-10-05T01:28:56.114652Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" Tokens:['another', 'cool', 'sentence', 'to', 'demonstrate', 'something', '.']\n"," Token IDs: [2178, 4658, 6251, 2000, 10580, 2242, 1012]\n"," input_ids:{'input_ids': [101, 2178, 4658, 6251, 2000, 10580, 2242, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"]}],"source":["print(f' Tokens:{tokens}')\n","print(f' Token IDs: {token_ids}')\n","print(f' input_ids:{input_ids}')"]},{"cell_type":"markdown","metadata":{},"source":["### Exercise: \n","Test different tokenizers, select models from the hub."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.126637Z","iopub.status.busy":"2023-10-05T01:28:56.126010Z","iopub.status.idle":"2023-10-05T01:28:56.134903Z","shell.execute_reply":"2023-10-05T01:28:56.133912Z","shell.execute_reply.started":"2023-10-05T01:28:56.126601Z"},"trusted":true},"outputs":[],"source":["#you can use this code\n","#tokenizer = AutoTokenizer.from_pretrained(\"[model]\")\n","#tokens = tokenizer.tokenize(\"Woaou another sentence!\")\n","#token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","#input_ids = tokenizer(\"Another cool sentence to demonstrate something.\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.136788Z","iopub.status.busy":"2023-10-05T01:28:56.136448Z","iopub.status.idle":"2023-10-05T01:28:56.146210Z","shell.execute_reply":"2023-10-05T01:28:56.145210Z","shell.execute_reply.started":"2023-10-05T01:28:56.136757Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" Tokens:['another', 'cool', 'sentence', 'to', 'demonstrate', 'something', '.']\n"," Token IDs: [2178, 4658, 6251, 2000, 10580, 2242, 1012]\n"," input_ids:{'input_ids': [101, 2178, 4658, 6251, 2000, 10580, 2242, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"]}],"source":["print(f' Tokens:{tokens}')\n","print(f' Token IDs: {token_ids}')\n","print(f' input_ids:{input_ids}')"]},{"cell_type":"markdown","metadata":{},"source":["## Batching"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.148036Z","iopub.status.busy":"2023-10-05T01:28:56.147635Z","iopub.status.idle":"2023-10-05T01:28:56.159893Z","shell.execute_reply":"2023-10-05T01:28:56.158926Z","shell.execute_reply.started":"2023-10-05T01:28:56.148006Z"},"trusted":true},"outputs":[],"source":["sentences = [\"Another cool sentence to demonstrate something.\",\n","           \"All I need is two sentences.\"]\n","batch = tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors=\"pt\") #pt for pyTorch"]},{"cell_type":"markdown","metadata":{},"source":["### Note:\n","All our sample will have the same length (necessity for the model) - tensors must have the same shape.\n","```\n","padding=True and truncation=True\n","```"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.162783Z","iopub.status.busy":"2023-10-05T01:28:56.161712Z","iopub.status.idle":"2023-10-05T01:28:56.172125Z","shell.execute_reply":"2023-10-05T01:28:56.171081Z","shell.execute_reply.started":"2023-10-05T01:28:56.162754Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n"," 'input_ids': tensor([[  101,  2178,  4658,  6251,  2000, 10580,  2242,  1012,   102],\n","        [  101,  2035,  1045,  2342,  2003,  2048, 11746,  1012,   102]])}\n"]}],"source":["pprint(batch)"]},{"cell_type":"markdown","metadata":{},"source":["Returns a dictionary with keys 'input_ids' and 'attention_mask', with two tensors the 'input ids' tensor and the 'attention_mask' tensor.\n","input_ids are unique ids."]},{"cell_type":"markdown","metadata":{},"source":["## Predictions"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.175042Z","iopub.status.busy":"2023-10-05T01:28:56.174286Z","iopub.status.idle":"2023-10-05T01:28:56.235479Z","shell.execute_reply":"2023-10-05T01:28:56.234562Z","shell.execute_reply.started":"2023-10-05T01:28:56.175013Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["SequenceClassifierOutput(loss=None,\n","                         logits=tensor([[-3.9261,  4.2183],\n","        [ 2.8756, -2.4102]]),\n","                         hidden_states=None,\n","                         attentions=None)\n","tensor([[2.9026e-04, 9.9971e-01],\n","        [9.9496e-01, 5.0376e-03]])\n","['POSITIVE', 'NEGATIVE']\n"]}],"source":["# Prevent gradient computation\n","\n","with torch.no_grad():\n","    outputs = model(**batch) \n","    predictions = torch.softmax(outputs.logits, dim=1)      # Apply softmax to convert model logits to probabilities\n","    labels = torch.argmax(predictions, dim=1)              # Find the index of the class with the highest probability for each example\n","    labels = [model.config.id2label[label_id] for label_id in labels.tolist()]\n","    pprint(outputs)\n","    pprint(predictions)\n","    pprint(labels)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.237212Z","iopub.status.busy":"2023-10-05T01:28:56.236846Z","iopub.status.idle":"2023-10-05T01:28:56.244170Z","shell.execute_reply":"2023-10-05T01:28:56.243187Z","shell.execute_reply.started":"2023-10-05T01:28:56.237180Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.0000, 1.0000],\n","        [0.9900, 0.0100]])\n"]}],"source":["# Define the number of decimal places to round to\n","decimal_places = 2\n","# Round the probabilities\n","rounded_probabilities = torch.round(predictions * 10**decimal_places) / (10**decimal_places)\n","# Print the rounded probabilities\n","print(rounded_probabilities)"]},{"cell_type":"markdown","metadata":{},"source":["### Saving"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.246373Z","iopub.status.busy":"2023-10-05T01:28:56.245722Z","iopub.status.idle":"2023-10-05T01:28:57.751592Z","shell.execute_reply":"2023-10-05T01:28:57.750613Z","shell.execute_reply.started":"2023-10-05T01:28:56.246340Z"},"trusted":true},"outputs":[],"source":["save_directory = \"your_dir\"\n","tokenizer.save_pretrained(save_directory)\n","model. save_pretrained(save_directory)\n","\n","tokenizer = AutoTokenizer.from_pretrained(save_directory)\n","model = AutoModelForSequenceClassification.from_pretrained(save_directory)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
