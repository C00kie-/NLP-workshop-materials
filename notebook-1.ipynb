{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Build a sentiment analysis pipeline with HuggingFace"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:44.894932Z","iopub.status.busy":"2023-10-05T01:28:44.894602Z","iopub.status.idle":"2023-10-05T01:28:53.396503Z","shell.execute_reply":"2023-10-05T01:28:53.395341Z","shell.execute_reply.started":"2023-10-05T01:28:44.894905Z"},"trusted":true},"outputs":[],"source":["#for colab\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:53.399472Z","iopub.status.busy":"2023-10-05T01:28:53.399069Z","iopub.status.idle":"2023-10-05T01:28:53.403849Z","shell.execute_reply":"2023-10-05T01:28:53.402951Z","shell.execute_reply.started":"2023-10-05T01:28:53.399433Z"},"trusted":true},"outputs":[],"source":["from transformers import pipeline\n","import torch\n","from pprint import pprint"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:53.406151Z","iopub.status.busy":"2023-10-05T01:28:53.405209Z","iopub.status.idle":"2023-10-05T01:28:54.358669Z","shell.execute_reply":"2023-10-05T01:28:54.357728Z","shell.execute_reply.started":"2023-10-05T01:28:53.406120Z"},"trusted":true},"outputs":[],"source":["classifier = pipeline(\"sentiment-analysis\")"]},{"cell_type":"markdown","metadata":{},"source":["We start by creating a \"Sentiment Analysis\" **classifier** using the pipeline function provided by the Hugging Face Transformers library. This function allows us to easily use pre-trained models for various natural language processing (NLP) tasks, like sentiment analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:54.361836Z","iopub.status.busy":"2023-10-05T01:28:54.360980Z","iopub.status.idle":"2023-10-05T01:28:54.408540Z","shell.execute_reply":"2023-10-05T01:28:54.407588Z","shell.execute_reply.started":"2023-10-05T01:28:54.361802Z"},"trusted":true},"outputs":[],"source":["results = classifier(\"This is cool\")\n","results"]},{"cell_type":"markdown","metadata":{},"source":["The model takes this text as input and predicts the sentiment associated with it. "]},{"cell_type":"markdown","metadata":{},"source":["Pipeline on Huggingface [documentation](https://huggingface.co/docs/transformers/main_classes/pipelines)"]},{"cell_type":"markdown","metadata":{},"source":["### More then one sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:54.410534Z","iopub.status.busy":"2023-10-05T01:28:54.410001Z","iopub.status.idle":"2023-10-05T01:28:54.508009Z","shell.execute_reply":"2023-10-05T01:28:54.507107Z","shell.execute_reply.started":"2023-10-05T01:28:54.410502Z"},"trusted":true},"outputs":[],"source":["# We give a list to the classifier now\n","results = classifier([\"NLP is nice\", \"It's a lot of work\"])\n","results"]},{"cell_type":"markdown","metadata":{},"source":["### Exercise:\n","\n","Add different text inputs with varying sentiments, run it, check the model's sentiment predictions, and explore how it assigns labels."]},{"cell_type":"markdown","metadata":{},"source":["## Now select a specific model into your pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:54.509823Z","iopub.status.busy":"2023-10-05T01:28:54.509514Z","iopub.status.idle":"2023-10-05T01:28:54.514246Z","shell.execute_reply":"2023-10-05T01:28:54.513239Z","shell.execute_reply.started":"2023-10-05T01:28:54.509792Z"},"trusted":true},"outputs":[],"source":["model_name = \"distilbert-base-uncased-finetuned-sst-2-english\""]},{"cell_type":"markdown","metadata":{},"source":["The model_name variable holds the name of the pre-trained model. In this case, it's \"distilbert-base-uncased-finetuned-sst-2-english\""]},{"cell_type":"markdown","metadata":{},"source":["Let's have a look at the model [card on Hugginface.co](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:54.516392Z","iopub.status.busy":"2023-10-05T01:28:54.515806Z","iopub.status.idle":"2023-10-05T01:28:55.355163Z","shell.execute_reply":"2023-10-05T01:28:55.354221Z","shell.execute_reply.started":"2023-10-05T01:28:54.516361Z"},"trusted":true},"outputs":[],"source":["classifier = pipeline(\"sentiment-analysis\", model=model_name)"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenizer"]},{"cell_type":"markdown","metadata":{},"source":["- Tokenization is the process of breaking down text into smaller **units** called **tokens**.\n","\n","- Tokens are the basic building blocks used by Transformers models to understand and process text.\n","\n","- Tokens can represent **words, subwords, or even individual characters**, depending on the model's vocabulary."]},{"cell_type":"markdown","metadata":{},"source":["![Pipeline](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg)"]},{"cell_type":"markdown","metadata":{},"source":["Source [image](https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:55.356719Z","iopub.status.busy":"2023-10-05T01:28:55.356390Z","iopub.status.idle":"2023-10-05T01:28:55.361422Z","shell.execute_reply":"2023-10-05T01:28:55.360527Z","shell.execute_reply.started":"2023-10-05T01:28:55.356689Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification"]},{"cell_type":"markdown","metadata":{},"source":["\"AutoModelForSequenceClassification\" adapts to various model architectures automatically."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:55.363556Z","iopub.status.busy":"2023-10-05T01:28:55.362893Z","iopub.status.idle":"2023-10-05T01:28:56.082049Z","shell.execute_reply":"2023-10-05T01:28:56.081052Z","shell.execute_reply.started":"2023-10-05T01:28:55.363525Z"},"trusted":true},"outputs":[],"source":["model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"markdown","metadata":{},"source":["When using from_pretrained, we are loading a pre-trained model and tokenizer specified by the model_name."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.085867Z","iopub.status.busy":"2023-10-05T01:28:56.085563Z","iopub.status.idle":"2023-10-05T01:28:56.105959Z","shell.execute_reply":"2023-10-05T01:28:56.105136Z","shell.execute_reply.started":"2023-10-05T01:28:56.085844Z"},"trusted":true},"outputs":[],"source":["classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["We create our sentiment analysis classifier."]},{"cell_type":"markdown","metadata":{},"source":["## Tokens to inputs IDs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.107623Z","iopub.status.busy":"2023-10-05T01:28:56.107285Z","iopub.status.idle":"2023-10-05T01:28:56.112778Z","shell.execute_reply":"2023-10-05T01:28:56.111516Z","shell.execute_reply.started":"2023-10-05T01:28:56.107593Z"},"trusted":true},"outputs":[],"source":["tokens = tokenizer.tokenize(\"Another cool sentence to demonstrate something.\")\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","input_ids = tokenizer(\"Another cool sentence to demonstrate something.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.114684Z","iopub.status.busy":"2023-10-05T01:28:56.114134Z","iopub.status.idle":"2023-10-05T01:28:56.124564Z","shell.execute_reply":"2023-10-05T01:28:56.123480Z","shell.execute_reply.started":"2023-10-05T01:28:56.114652Z"},"trusted":true},"outputs":[],"source":["print(f' Tokens:{tokens}')\n","print(f' Token IDs: {token_ids}')\n","print(f' input_ids:{input_ids}')"]},{"cell_type":"markdown","metadata":{},"source":["### Exercise: \n","Test different tokenizers, select models from the hub."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.126637Z","iopub.status.busy":"2023-10-05T01:28:56.126010Z","iopub.status.idle":"2023-10-05T01:28:56.134903Z","shell.execute_reply":"2023-10-05T01:28:56.133912Z","shell.execute_reply.started":"2023-10-05T01:28:56.126601Z"},"trusted":true},"outputs":[],"source":["#you can use this code\n","#tokenizer = AutoTokenizer.from_pretrained(\"[model]\")\n","#tokens = tokenizer.tokenize(\"Woaou another sentence!\")\n","#token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","#input_ids = tokenizer(\"Another cool sentence to demonstrate something.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.136788Z","iopub.status.busy":"2023-10-05T01:28:56.136448Z","iopub.status.idle":"2023-10-05T01:28:56.146210Z","shell.execute_reply":"2023-10-05T01:28:56.145210Z","shell.execute_reply.started":"2023-10-05T01:28:56.136757Z"},"trusted":true},"outputs":[],"source":["print(f' Tokens:{tokens}')\n","print(f' Token IDs: {token_ids}')\n","print(f' input_ids:{input_ids}')"]},{"cell_type":"markdown","metadata":{},"source":["## Batching"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.148036Z","iopub.status.busy":"2023-10-05T01:28:56.147635Z","iopub.status.idle":"2023-10-05T01:28:56.159893Z","shell.execute_reply":"2023-10-05T01:28:56.158926Z","shell.execute_reply.started":"2023-10-05T01:28:56.148006Z"},"trusted":true},"outputs":[],"source":["sentences = [\"Another cool sentence to demonstrate something.\",\n","           \"All I need is two sentences.\"]\n","batch = tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors=\"pt\") #pt for pyTorch"]},{"cell_type":"markdown","metadata":{},"source":["### Note:\n","All our sample will have the same length (necessity for the model) - tensors must have the same shape.\n","```\n","padding=True and truncation=True\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.162783Z","iopub.status.busy":"2023-10-05T01:28:56.161712Z","iopub.status.idle":"2023-10-05T01:28:56.172125Z","shell.execute_reply":"2023-10-05T01:28:56.171081Z","shell.execute_reply.started":"2023-10-05T01:28:56.162754Z"},"trusted":true},"outputs":[],"source":["pprint(batch)"]},{"cell_type":"markdown","metadata":{},"source":["Returns a dictionary with keys 'input_ids' and 'attention_mask', with two tensors the 'input ids' tensor and the 'attention_mask' tensor.\n","input_ids are unique ids."]},{"cell_type":"markdown","metadata":{},"source":["## Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.175042Z","iopub.status.busy":"2023-10-05T01:28:56.174286Z","iopub.status.idle":"2023-10-05T01:28:56.235479Z","shell.execute_reply":"2023-10-05T01:28:56.234562Z","shell.execute_reply.started":"2023-10-05T01:28:56.175013Z"},"trusted":true},"outputs":[],"source":["# Prevent gradient computation\n","\n","with torch.no_grad():\n","    outputs = model(**batch) \n","    predictions = torch.softmax(outputs.logits, dim=1)      # Apply softmax to convert model logits to probabilities\n","    labels = torch.argmax(predictions, dim=1)              # Find the index of the class with the highest probability for each example\n","    labels = [model.config.id2label[label_id] for label_id in labels.tolist()]\n","    pprint(outputs)\n","    pprint(predictions)\n","    pprint(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.237212Z","iopub.status.busy":"2023-10-05T01:28:56.236846Z","iopub.status.idle":"2023-10-05T01:28:56.244170Z","shell.execute_reply":"2023-10-05T01:28:56.243187Z","shell.execute_reply.started":"2023-10-05T01:28:56.237180Z"},"trusted":true},"outputs":[],"source":["# Define the number of decimal places to round to\n","decimal_places = 2\n","# Round the probabilities\n","rounded_probabilities = torch.round(predictions * 10**decimal_places) / (10**decimal_places)\n","# Print the rounded probabilities\n","print(rounded_probabilities)"]},{"cell_type":"markdown","metadata":{},"source":["### Saving"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-05T01:28:56.246373Z","iopub.status.busy":"2023-10-05T01:28:56.245722Z","iopub.status.idle":"2023-10-05T01:28:57.751592Z","shell.execute_reply":"2023-10-05T01:28:57.750613Z","shell.execute_reply.started":"2023-10-05T01:28:56.246340Z"},"trusted":true},"outputs":[],"source":["save_directory = \"your_dir\"\n","tokenizer.save_pretrained(save_directory)\n","model. save_pretrained(save_directory)\n","\n","tokenizer = AutoTokenizer.from_pretrained(save_directory)\n","model = AutoModelForSequenceClassification.from_pretrained(save_directory)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
